---
layout: default
description: How to deal with Alerts from SOS GAP checking tools
service: Security
title: GAP Alert - No Bigfix healthcheck results
runbook-name: "SOS Bigfix no healthcheck results"
playbooks: [""]
failure: ["SOS reporting no bigfix healthcheck results"]
link: /compliance_gap_alert_bigfix_no_healthcheck_results.html
type: Troubleshooting
parent: Armada Runbooks

---

Troubleshooting
{: .label .label-red}

# GAP Alert - No Bigfix healthcheck results

## Overview

This runbook helps deal with SOS reporting that a machine has no healthcheck results for at least 72 hours.

## Background

As part of security compliance of Armada systems, it is a requirement that SOS Bigfix is installed.  This is a tool which applied either to `kube` machines via the `csutil` tool, or via the `condutors-bootstrap` process.

This check will report any systems which are registered under ALC c_code which have never reporting back to SOS.

The GHE issues and any alerts for this process are generated in this [jenkins job](https://alchemy-conductors-jenkins.swg-devops.com/view/Conductors/job/Conductors/job/Security-Compliance/job/compliance-bigfix-no-health-check-results/)


## Example alert(s)

A GHE issue will be created in [github alchemy-conductors/team](https://github.ibm.com/alchemy-conductors/team) titled `GAP ALERT - XX - machines with no BigFix healthcheck require investigation` where `XX` is the number of machines with issues. 

No pagerduty alerts are generated by this monitoring.

## Investigation and Action

There are usually two reasons why machines have no entries 

1.  They are brand new or OSReloaded machines and the SOS Bigfix tooling has not been installed, usually as a result of a bootstrap failure; or
2.  They are kube machines which need the `csutil` re-running against the IBM Cloud cluster they are part of.

### For Non kube machines.

Check list for machines not starting `kube`

-   Attempt to ssh to the machine  
_If you can, continue with the below sub-checks_
  -  Check `/opt/` for a file starting `ws.<machinename>` 
     - if this doesn't exits, then a bootstrap has never completed on this machine. Follow the instructions for [re-running a bootstrap](#bootstrap-a-machine) and then monitor that it completes.
  - if this file does exits, check it for errors.  It's likely a bootstrap failed to fully complete as the SOS tools are installed towards the end of the bootstrap process.  Examine the log and either
    - Re-run a bootstrap by following [re-running instructions](#bootstrap-a-machine) as in most circumstances, it's a transient error; or
    - If a re-run also fails, attempt to fix the problem that failed  (if you know how to); or
    - Go-to the [escalation](#escalation) section below.

-  If you cannot SSH to the machine or ssh with your userid fails
  -  Find the machine in [softlayer](https://control.softlayer.com/) and attempt logging in as `root` 
  - If root access works, [re-run a bootstrap](#bootstrap-a-machine) from the command line.

- If the machine is completely unreachable, check the machines `start` date and the `reload` date in Softlayer.  If this is recent, then there is a chance the reload failed.  
  - Search for other [conductors team tickets](https://github.ibm.com/alchemy-conductors/team#workspaces/team-flow-work-57d171d400ae1856799252fa/boards?repos=61104&showClosed=false) mentioning this server and reach out to the SRE who may be working on this node.
  -  Check [LogDNA for igorina](https://app.us-south.logging.cloud.ibm.com/ca1620a740/logs/view/a437ecc672?q=10.184.8.188&apps=g%3A%3Af0a120a309,g%3A%3A8d675402a1,g%3A%3Ac41214415a) for entries for this server.  
    - Has it been reloaded recently?  It may have failed reload.  If that is the case, [follow the section for reloading below](#reloading-a-machine)


### For kube machines

-  Get details about the cluster  
In the [#armada-xo channel in Slack](https://ibm-argonauts.slack.com/messages/G53AJ95TP) lookup the cluster using clusterid from the machine name  
e.g. cluster id from worker id `kube-fra02-cr19eef897d2934eb2914ca3486aa10276-w1` is `19eef897d2934eb2914ca3486aa10276`  
   In the output should be details of the cluster such as the name.
   ~~~~
   Retrieving cluster identified by 19eef897d2934eb2914ca3486aa10276 in region: eu-de, environment: bluemix, carrier: carrier1
   {
   "Region": "eu-de",
   "ClusterID": "19eef897d2934eb2914ca3486aa10276",
   "Name": "infra-accessallareas",
   ~~~~
- Only un-onboarded clusters should ever appear in this list.  Use the name to try and identify the cluster which these workers belong to.  If you are in doubt, speak to the SRE Leads as to whether this cluster is one we manage and need to onboard.
- Follow instructions [here](./development_onboard_sos_tools.html) to (re)deploy the csutil tooling to the kube cluster.

### Escalation

If you have exhausted all of the lines of investigation, then consult with the SRE leads what to do next.


### Bootstrap a machine

To re-run a bootstrap, follow the documentation [here](./bootstrap_executing_and_debugging.html)

_NB_ If you can ssh to the server, the command line driven bootstrap is probably the quickest way to invoke the bootstrap.


### Reloading a machine

Reloads differ depending on machine type.

For Armada worker nodes, use igorina  
`reload <node> outage:0`

For any other node type, consult with your SRE lead.

## Escalation Policy

[Conductors](https://ibm.pagerduty.com/escalation_policies#PZRV4HB)
