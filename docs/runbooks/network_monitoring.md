---
layout: default
service: Network Intelligence
title: Network monitoring of Alchemy infrastructure
runbook-name: Network monitoring of Alchemy infrastructure
description: How Netint monitors non-k8s Alchemy infrastructure, e.g. vyattas, haproxies
playbooks: ["NoPlaybooksSpecified"]
failure: ["NoFailuresSpecified"]
link: /runbooks/network_monitoring.html
type: Informational
parent: Armada Runbooks

---

Informational
{: .label }

## Overview

The NetInt core infrastructure monitoring and alerting stack is based on [Prometheus and Alertmanager](https://prometheus.io/).

## Detailed Information

### Infrastructure

Our Prometheus and Alertmanager instances run in the netint namespace on the infra-accessallareas cluster in the support account. The monitoring stack consists of 4 containers with a deployment per environment:

```
prometheus-stack-dev-mon01-alertmanager-84fb5567b9-nvr5f        1/1     Running   0          4d18h
prometheus-stack-dev-mon01-grafana-868cdfd976-4czmg             1/1     Running   0          4d19h
prometheus-stack-dev-mon01-prometheus-6558d5b98d-sf2t6          1/1     Running   0          4d18h
prometheus-stack-dev-mon01-vialli-655fddfc98-jx54d              2/2     Running   12         4d18h
prometheus-stack-prestage-mon01-alertmanager-76d8f9d479-4vmtl   1/1     Running   0          4d18h
prometheus-stack-prestage-mon01-grafana-f4bdb5bd4-wsbls         1/1     Running   0          4d19h
prometheus-stack-prestage-mon01-prometheus-785df56cdd-625v4     1/1     Running   1          4d18h
prometheus-stack-prestage-mon01-vialli-c8959756b-jxswt          2/2     Running   2          4d18h
prometheus-stack-prod-dal09-alertmanager-7689cc5f7c-4bnh5       1/1     Running   0          3d22h
prometheus-stack-prod-dal09-grafana-86d7486c96-ztrl5            1/1     Running   0          4d18h
prometheus-stack-prod-dal09-prometheus-6755b7fd-6zmbt           2/2     Running   17         3d22h
prometheus-stack-prod-dal09-vialli-6854c6d9fc-6rgqc             2/2     Running   13         3d22h
prometheus-stack-prod-lon02-alertmanager-545dfbb655-qnhcd       1/1     Running   0          4d18h
prometheus-stack-prod-lon02-grafana-55f99c4b58-sglgj            1/1     Running   0          4d18h
prometheus-stack-prod-lon02-prometheus-5f65c9ccb5-62s2d         2/2     Running   9          3d22h
prometheus-stack-prod-lon02-vialli-54d7bff56-k9t9p              2/2     Running   13         3d22h
prometheus-stack-prod-tok02-alertmanager-84b79b5b9c-j8m2f       1/1     Running   0          4d18h
prometheus-stack-prod-tok02-grafana-7fd7946d69-6f5j5            1/1     Running   0          4d18h
prometheus-stack-prod-tok02-prometheus-697785dbff-sn4wm         1/1     Running   31         4d17h
prometheus-stack-prod-tok02-vialli-67b65b6ddc-ndp2h             2/2     Running   10         4d18h
prometheus-stack-prodfr2-par04-alertmanager-859dcd9856-k8ncq    1/1     Running   0          10d
prometheus-stack-prodfr2-par04-grafana-6f76b657fb-xmprz         1/1     Running   0          10d
prometheus-stack-prodfr2-par04-prometheus-bccd955b5-8fftm       1/1     Running   3          6d12h
prometheus-stack-prodfr2-par04-vialli-6f9f968d7f-r8mrx          2/2     Running   0          10d
prometheus-stack-stage-dal09-alertmanager-679b8545cc-bp8cd      1/1     Running   0          4d18h
prometheus-stack-stage-dal09-grafana-647dcb8cc5-bgpkg           1/1     Running   0          4d19h
prometheus-stack-stage-dal09-prometheus-7d7bcd6c74-kz28b        1/1     Running   8          4d18h
prometheus-stack-stage-dal09-vialli-5ccbcc95b8-kzv4k            2/2     Running   6          4d18h
prometheus-stack-sup-wdc04-alertmanager-78dd9b98d5-vhswb        1/1     Running   0          4d18h
prometheus-stack-sup-wdc04-grafana-c49cd46bf-8vn4g              1/1     Running   0          4d19h
prometheus-stack-sup-wdc04-prometheus-6fd7bbd87d-r6fln          1/1     Running   6          4d18h
prometheus-stack-sup-wdc04-vialli-74b7cb499b-6xsf2              2/2     Running   1          4d18h
```

The configurations for each prometheus instance are generated by the [monitoring-config-generator](https://alchemy-containers-jenkins.swg-devops.com/job/Network-Intelligence/job/monitoring-config-generator/configure) jenkins job, this job is automatically run when changes are committed to the [ansible-inventory](https://github.ibm.com/alchemy-netint/ansible-inventory) repository.

### Inventories

Our Ansible Inventories are automatically generated based on the machines that are in Softlayer. We use hostname naming conventions in order to figure out programmatically what a machine is, and therefore which inventory it should be in.

[network-source](https://github.ibm.com/alchemy-netint/network-source) is updated every 30 minutes by the [softlayer-query-generator](https://alchemy-containers-jenkins.swg-devops.com/view/Network-Intelligence/job/Network-Intelligence/job/softlayer-query-generator/) Jenkins job.

When `network-source` is updated, the [generate-ansible-inventory](https://alchemy-containers-jenkins.swg-devops.com/view/Network-Intelligence/job/Network-Intelligence/job/generate-ansible-inventory/) Jenkins job is triggered, which uses the [generate-ansible-inventory](https://github.ibm.com/alchemy-netint/generate-ansible-inventory) repository to convert the `csv` files into ansible inventory syntax.

These inventories are checked into [ansible-inventory](https://github.ibm.com/alchemy-netint/ansible-inventory).

### Machines we monitor

The following is a list of general machine types we monitor along with an example of a hostname for one of these and which inventory file they come from.

- Vyattas e.g. `prod-dal09-firewall-vyattaha1-01` in the [vyattas inventory](https://github.ibm.com/alchemy-netint/ansible-inventory/blob/master/inventory/vyattas)
- Carrier Haproxy machines e.g. `prod-dal10-carrier3-haproxy-01` in the [loadbalancer-hosts inventory](https://github.ibm.com/alchemy-netint/ansible-inventory/blob/master/inventory/loadbalancer-hosts)
- Inquisition external portables e.g. `prod-dal10-inq-prometheus-01` in the [inquisition inventory](https://github.ibm.com/alchemy-netint/ansible-inventory/blob/master/inventory/inquisition)

## Detecting networking issues

We have two methods of detecting issues.

### [Alerting Rules](https://github.ibm.com/alchemy-netint/prometheus-rules)

Prometheus Rules contains the alerting rules for both low and high priority (page-out worthy) alerts.

The rules themselves are organised into various folders, divided by environment (i.e. `dev`, `prestage`, `sup`, `stage`, `prod`). These folders are for rules which only apply to the environment the folder is named for. There is also a `common` folder whose rules get deployed everywhere.

An example of an alerting rule looks like this:

```
# Alert for any instance that is unreachable for >5m (10 * scrape interval). Temporarily increased due to packetloss to Wat/Pa vyattas.
ALERT InstanceDown
  IF up{job!="inquisition-pods"} == 0
  FOR 5m
  LABELS { destination = "netint" }
  ANNOTATIONS {
    summary = "Instance {% raw %}{{ $labels.instance }}{% endraw %} is down",
    description = "{% raw %}{{ $labels.instance }}{% endraw %} has been down for more than 5 minutes.",
    runbook = "https://pages.github.ibm.com/alchemy-conductors/documentation-pages/docs/runbooks/netint_alertmanager_checks.html#issue-instance-prod-firewall-vyatta--is-down",
  }
```

You can read more about how alerting rules are constructed in the [Prometheus documentation](https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/).

Of special interest to us are the `destination` labels which we use to decide how an alert is routed;

- `netint` - High priority Pagerduty alert to [Alchemy - Network Intel 24x7](https://bluemix.pagerduty.com/escalation_policies#PSB1EKU) escalation policy
- `slack_only` - [#netint](https://ibm-argonauts.slack.com/messages/C53PUD2TE) Slack channel only
- `conductors` - High priority Pagerduty alert to Conductors

and the `runbook` annotation. This contains a link to a documentation page with runbooks which are there to help debug and fix the problem if you are unfamiliar with the alert. Most of our runbooks for core infrastructure alerts are [here](https://pages.github.ibm.com/alchemy-conductors/documentation-pages/docs/runbooks/netint_alertmanager_checks.html).

### Monitoring graphs

Network monitoring graphs per environment and are available 

There are four dashboards per environment:

1. **Vyatta Dashboard** - graphs relating to the vyattas operated by NetInt
2. **Carrier Load Balancer** - graphs relating to the carrier load balancer "haproxy" machines operated by Netint
3. **Monitoring monitoring** - tracks the conntrack table size of haproxies separately
4. **Env Status** - high level overview of the health of the entire environment
5. **Ping Dashboard** - overview of network ping time between different locations
